import scanpy as sc
import anndata
import os
import glob

# ğŸ”¹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì • (í•˜ìœ„ í´ë” í¬í•¨)
data_dir = "/data1/BLA_projection_2/Data/Resources/.v2/after_preprocessing"

# ğŸ”¹ í•˜ìœ„ í´ë” í¬í•¨ .h5ad íŒŒì¼ ì „ì²´ ê²€ìƒ‰
adata_paths = sorted(glob.glob(os.path.join(data_dir, "**", "*.h5ad"), recursive=True))

# ğŸ”¹ ê°œë³„ íŒŒì¼ ë¡œë“œ
adata_list = [sc.read_h5ad(p) for p in adata_paths]

# ğŸ”¹ ìƒ˜í”Œ ì´ë¦„ ì¶”ì¶œ (í´ë”/íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ìƒì„±)
sample_keys = [os.path.splitext(os.path.basename(p))[0] for p in adata_paths]

# ğŸ”¹ Concat ìˆ˜í–‰
adata_all = anndata.concat(adata_list, join="outer", label="sample", keys=sample_keys)

# ğŸ”¹ ì €ì¥ ê²½ë¡œ ì„¤ì • ë° ì €ì¥
save_path = os.path.join(data_dir, "adata_all_concat.h5ad")
adata_all.write(save_path)

print(f"âœ… Concat ì™„ë£Œ ë° ì €ì¥ ê²½ë¡œ: {save_path}")

import scanpy as sc

adata_all = sc.read_h5ad("/data1/BLA_projection_2/Data/Resources/.v2/after_preprocessing/adata_all_concat.h5ad")
# Normalize â†’ log1p ì ìš©
sc.pp.normalize_total(adata_all, target_sum=1e4)
sc.pp.log1p(adata_all)

# ë¯¸í† ì½˜ë“œë¦¬ì•„ ìœ ì „ì ë¹„ìœ¨ ê³„ì‚°
adata_all.var['mt'] = adata_all.var_names.str.startswith('mt-')
sc.pp.calculate_qc_metrics(adata_all, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)

sc.pl.violin(adata_all, ['total_counts', 'n_genes_by_counts', 'pct_counts_mt'], groupby='sample', multi_panel=True)


import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# sample ì´ë¦„ ê°„ë‹¨íˆ ì •ì œ (ì´ë¯¸ í–ˆìœ¼ë©´ ìƒëµ ê°€ëŠ¥)
adata_all.obs['sample'] = adata_all.obs['sample'].str.replace("BLA_projection_sample_", "", regex=False)

# í•„ìš”í•œ ë°ì´í„°í”„ë ˆì„ ì¶”ì¶œ
qc_df = adata_all.obs[['sample', 'n_genes_by_counts', 'pct_counts_mt']].copy()


# ë¯¸í† ì½˜ë“œë¦¬ì•„ ìœ ì „ì ë¹„ìœ¨ ê³„ì‚°
adata_all.var['mt'] = adata_all.var_names.str.startswith('mt-')
sc.pp.calculate_qc_metrics(adata_all, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)

# QC metric ì‹œê°í™”
sc.pl.violin(adata_all, ['total_counts', 'n_genes_by_counts', 'pct_counts_mt'], groupby='sample', multi_panel=True)


# PCA ê³„ì‚° ë° layer ì €ì¥
sc.pp.highly_variable_genes(adata_all, flavor='seurat', n_top_genes=2000, subset=True)
sc.pp.scale(adata_all, max_value=10)
sc.tl.pca(adata_all, svd_solver='arpack')

# UMAP ê³„ì‚°
sc.pp.neighbors(adata_all, n_neighbors=15, n_pcs=30)
sc.tl.umap(adata_all)
sc.pl.umap(adata_all, color=['sample', 'total_counts', 'pct_counts_mt'])


%pip install harmonypy

import harmonypy as hm

# Harmony ì ìš© ì „ neighbors ì¬ê³„ì‚°
sc.pp.pca(adata_all, svd_solver='arpack')
ho = hm.run_harmony(adata_all.obsm['X_pca'], adata_all.obs, 'sample')
adata_all.obsm['X_pca_harmony'] = ho.Z_corr.T

# UMAP (Harmony)
sc.pp.neighbors(adata_all, use_rep='X_pca_harmony')
sc.tl.umap(adata_all)
sc.pl.umap(adata_all, color=['sample', 'total_counts', 'pct_counts_mt'], title='Harmony UMAP')


from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# ğŸ”¹ ë‹¤ì–‘í•œ resolutionì— ëŒ€í•´ ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°
resolutions = [0.2, 0.4, 0.6, 0.8, 1.0]
scores = {}

for res in resolutions:
    # Leiden clustering ìˆ˜í–‰ (Harmony latent ê¸°ë°˜)
    sc.tl.leiden(adata_all, resolution=res, key_added=f'leiden_{res}')
    
    # ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°
    labels = adata_all.obs[f'leiden_{res}']
    score = silhouette_score(adata_all.obsm['X_pca_harmony'], labels)
    scores[res] = score
    print(f"ğŸ”¹ resolution={res:.1f} â†’ silhouette_score={score:.4f}")

# ğŸ”¹ ì‹œê°í™”
plt.figure(figsize=(6,4))
plt.plot(list(scores.keys()), list(scores.values()), marker='o')
plt.xlabel("Leiden Resolution")
plt.ylabel("Silhouette Score")
plt.title("Resolution vs Silhouette Score")
plt.grid(True)
plt.tight_layout()
plt.show()

# ğŸ”¹ ìµœì  resolutionìœ¼ë¡œ Leiden clustering ìˆ˜í–‰
sc.tl.leiden(adata_all, resolution=0.2, key_added='leiden_0.2')

# ğŸ”¹ UMAP ì‹œê°í™” (í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„)
sc.pl.umap(
    adata_all,
    color='leiden_0.2',
    palette='tab20',  # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì • (ìµœëŒ€ 20ê°œ í´ëŸ¬ìŠ¤í„°ê¹Œì§€)
    legend_loc='on data',  # UMAP ìœ„ì— label í‘œì‹œ
    title='Leiden Clustering (resolution=0.2)'
)

# ğŸ”¹ í´ëŸ¬ìŠ¤í„°ë³„ marker gene íƒìƒ‰
sc.tl.rank_genes_groups(
    adata_all,
    groupby='leiden_0.2',
    method='wilcoxon',  # ë˜ëŠ” 't-test', 'logreg'
    key_added='rank_genes_leiden_0.2'
)

# ğŸ”¹ ìƒìœ„ marker ìœ ì „ì ì‹œê°í™”
sc.pl.rank_genes_groups(
    adata_all,
    key='rank_genes_leiden_0.2',
    n_genes=10,  # í´ëŸ¬ìŠ¤í„°ë‹¹ ìƒìœ„ 10ê°œ
    sharey=False
)

%pip show celltypist

import celltypist
from celltypist.models import Model

from celltypist.models import Model, download_models

import scanpy as sc

import numpy as np

# ì´ ì¹´ìš´íŠ¸ë¥¼ 10,000ìœ¼ë¡œ ì •ê·œí™”
sc.pp.normalize_total(adata_all, target_sum=1e4)

# log1p ë³€í™˜
sc.pp.log1p(adata_all)

adata_all.X = np.nan_to_num(adata_all.X)


# ğŸ”¹ 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
model_path = download_models(model='Mouse_Whole_Brain.pkl')  # ì´ë¦„ì— ê³µë°± âŒ, ì–¸ë”ìŠ¤ì½”ì–´ âœ…

# ğŸ”¹ 2. ëª¨ë¸ ë¡œë“œ
model = Model.load('Mouse_Whole_Brain.pkl')

# ğŸ”¹ 3. CellTypist ì˜ˆì¸¡ ì‹¤í–‰
results = celltypist.annotate(adata_all, model=model, majority_voting=True)


# 1. í´ëŸ¬ìŠ¤í„° ë‹¨ìœ„ë¡œ celltypist ì‹¤í–‰
results = celltypist.annotate(adata_all, model=model, majority_voting=True)

# 2. í´ëŸ¬ìŠ¤í„° ë‹¨ìœ„ ê²°ê³¼ â†’ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥ (cluster ID â†’ cell type)
cluster_labels = results.predicted_labels
cluster_to_celltype = dict(zip(cluster_labels.index.astype(str), cluster_labels.values))

# 3. í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° cellì— í•´ë‹¹ cell type í• ë‹¹
adata_all.obs['celltypist'] = adata_all.obs['leiden_0.2'].map(cluster_to_celltype)



